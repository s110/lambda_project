# Scraper Serverless de Datos Inmobiliarios en AWS

Este proyecto implementa un sistema de web scraping automatizado, escalable y eficiente en costos para extraer datos de propiedades inmobiliarias del sitio web `infocasas.com.pe`. La arquitectura est√° completamente basada en servicios serverless de AWS, lo que garantiza un bajo mantenimiento y un modelo de pago por uso.

## üéØ Objetivo del Proyecto

El objetivo principal es recopilar, enriquecer y almacenar informaci√≥n detallada de propiedades en venta (precio, ubicaci√≥n, caracter√≠sticas, coordenadas geogr√°ficas, etc.) de forma peri√≥dica y autom√°tica. Los datos recopilados se almacenan en una base de datos NoSQL (Amazon DynamoDB), dej√°ndolos listos para ser consumidos por otros servicios, como an√°lisis de datos, APIs o paneles de visualizaci√≥n.

## üèõÔ∏è Arquitectura de la Soluci√≥n

La soluci√≥n utiliza un patr√≥n de dise√±o **"Fan-Out"** para desacoplar las tareas y permitir un procesamiento paralelo y resiliente. Esto evita los timeouts de las funciones Lambda y distribuye la carga de trabajo de manera eficiente.


### Flujo de Trabajo:

1.  **Disparo Programado**: Un disparador de **Amazon EventBridge** se activa seg√∫n una programaci√≥n definida (p. ej., una vez al d√≠a).
2.  **Orquestaci√≥n**: El disparador invoca una funci√≥n **AWS Lambda ("Orchestrator")**. Esta funci√≥n es responsable de:
    *   Navegar por las p√°ginas de listado del sitio web.
    *   Extraer los datos b√°sicos de cada propiedad.
    *   Enviar cada propiedad como un mensaje individual a una cola de **Amazon SQS**.
3.  **Cola de Tareas**: La cola de **Amazon SQS** act√∫a como un b√∫fer, almacenando de forma fiable todas las "tareas" (propiedades a procesar) pendientes.
4.  **Procesamiento en Paralelo**: La cola SQS activa una segunda funci√≥n **AWS Lambda ("Worker")** por cada lote de mensajes. Gracias a la escalabilidad de Lambda, m√∫ltiples workers pueden ejecutarse en paralelo. Cada worker:
    *   Recibe un mensaje con los datos de una propiedad.
    *   Realiza una segunda petici√≥n al sitio web para visitar la p√°gina de detalle y extraer informaci√≥n adicional (en este caso, las coordenadas geogr√°ficas).
    *   Limpia y formatea el registro completo para que sea compatible con la base de datos.
5.  **Almacenamiento**: El worker guarda el registro final y enriquecido como un √≠tem en una tabla de **Amazon DynamoDB**.

